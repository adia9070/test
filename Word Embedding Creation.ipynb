{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_master = pd.read_csv(\"data/imdb_master.csv\")\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_master['review'] = imdb_master.review.str.lower()\n",
    "imdb_master['review'] = imdb_master.review.str.strip()\n",
    "imdb_master['review'] = imdb_master.review.str.replace(\"[0-9!\\\"#$%&()*+,-./:;<=>?@[\\]^_`Â´{|}~]\",\" \")\n",
    "imdb_master['review'] = imdb_master.review.str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = imdb_master.review.values.tolist() \n",
    "\n",
    "tok_review = [i.split() for i in review]\n",
    "\n",
    "filter_tok_review = list()\n",
    "for i in tok_review:\n",
    "    temp_list = list()\n",
    "    for j in i:\n",
    "        if j not in stop_words:\n",
    "            temp_list.append(j)\n",
    "    filter_tok_review.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filter_tok_review)  #tokenize review not containing the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = Word2Vec(\n",
    "        filter_tok_review,\n",
    "        size=100,\n",
    "        window=4,\n",
    "        min_count=2,\n",
    "        workers=4,\n",
    "        iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'imdb_master_embedding_word2vec_100k_100.txt'\n",
    "model_w2v.wv.save_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('presidency', 0.6846837997436523),\n",
       " ('elected', 0.6584633588790894),\n",
       " ('senator', 0.6514028310775757),\n",
       " ('governor', 0.6488013863563538),\n",
       " ('bush', 0.6360360980033875),\n",
       " ('administration', 0.6246280670166016),\n",
       " ('assassinated', 0.616852879524231),\n",
       " ('mayor', 0.5997281074523926),\n",
       " ('presidential', 0.5929844975471497),\n",
       " ('colonel', 0.5780386328697205)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar('president')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
